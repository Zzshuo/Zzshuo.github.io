<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>shardingsphere介绍</title>
    <link href="/2021/01/05/shardingsphere-introduce/"/>
    <url>/2021/01/05/shardingsphere-introduce/</url>
    
    <content type="html"><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p><a href="https://shardingsphere.apache.org/">ShardingSphere 官网</a></p><p>Apache ShardingSphere 是一套开源的分布式数据库中间件解决方案组成的生态圈，它由 JDBC、Proxy 和 Sidecar（规划中）这 3 款相互独立，却又能够混合部署配合使用的产品组成。 它们均提供标准化的数据分片、分布式事务和数据库治理功能，可适用于如 Java 同构、异构语言、云原生等各种多样化的应用场景。</p><p>Apache ShardingSphere 定位为关系型数据库中间件，旨在充分合理地在分布式的场景下利用关系型数据库的计算和存储能力，而并非实现一个全新的关系型数据库。 它通过关注不变，进而抓住事物本质。关系型数据库当今依然占有巨大市场，是各个公司核心业务的基石，未来也难于撼动，我们目前阶段更加关注在原有基础上的增量，而非颠覆。</p><p>Apache ShardingSphere 5.x 版本开始致力于可插拔架构，项目的功能组件能够灵活的以可插拔的方式进行扩展。 目前，数据分片、读写分离、数据加密、影子库压测等功能，以及对 MySQL、PostgreSQL、SQLServer、Oracle 等 SQL 与协议的支持，均通过插件的方式织入项目。 开发者能够像使用积木一样定制属于自己的独特系统。Apache ShardingSphere 目前已提供数十个 SPI 作为系统的扩展点，而且仍在不断增加中。</p><p>ShardingSphere 已于2020年4月16日成为 <a href="https://apache.org/index.html#projects-list">Apache 软件基金会</a>的顶级项目。</p><h3 id="ShardingSphere-JDBC"><a href="#ShardingSphere-JDBC" class="headerlink" title="ShardingSphere-JDBC"></a>ShardingSphere-JDBC</h3><p>定位为轻量级 Java 框架，在 Java 的 JDBC 层提供的额外服务。 它使用客户端直连数据库，以 jar 包形式提供服务，无需额外部署和依赖，可理解为增强版的 JDBC 驱动，完全兼容 JDBC 和各种 ORM 框架。</p><ul><li>适用于任何基于 JDBC 的 ORM 框架，如：JPA, Hibernate, Mybatis, Spring JDBC Template 或直接使用 JDBC。</li><li>支持任何第三方的数据库连接池，如：DBCP, C3P0, BoneCP, Druid, HikariCP 等。</li><li>支持任意实现 JDBC 规范的数据库，目前支持 MySQL，Oracle，SQLServer，PostgreSQL 以及任何遵循 SQL92 标准的数据库。</li></ul><p><img src="/images/shardingsphere-introduce/image-20201216153825102.png" alt="image-20201216153825102"></p><h3 id="ShardingSphere-Proxy"><a href="#ShardingSphere-Proxy" class="headerlink" title="ShardingSphere-Proxy"></a>ShardingSphere-Proxy</h3><p>定位为透明化的数据库代理端，提供封装了数据库二进制协议的服务端版本，用于完成对异构语言的支持。 目前提供 MySQL 和 PostgreSQL 版本，它可以使用任何兼容 MySQL/PostgreSQL 协议的访问客户端(如：MySQL Command Client, MySQL Workbench, Navicat 等)操作数据，对 DBA 更加友好。</p><ul><li>向应用程序完全透明，可直接当做 MySQL/PostgreSQL 使用。</li><li>适用于任何兼容 MySQL/PostgreSQL 协议的的客户端。</li></ul><p><img src="/images/shardingsphere-introduce/shardingsphere-proxy-brief.png" alt="ShardingSphere-Proxy Architecture"></p><h3 id="ShardingSphere-Scaling"><a href="#ShardingSphere-Scaling" class="headerlink" title="ShardingSphere-Scaling"></a>ShardingSphere-Scaling</h3><p>ShardingSphere-Scaling 是一个提供给用户的通用的 ShardingSphere 数据接入迁移，及弹性伸缩的解决方案。</p><h3 id="ShardingSphere-UI"><a href="#ShardingSphere-UI" class="headerlink" title="ShardingSphere-UI"></a>ShardingSphere-UI</h3><p>ShardingSphere-UI 是 ShardingSphere 的一个简单而有用的web管理控制台。它用于帮助用户更简单的使用 ShardingSphere 的相关功能，目前提供注册中心管理、动态配置管理、数据库编排等功能。</p><p>项目结构上采取了前后端分离的方式，前端使用 Vue 框架，后端采用 Spring Boot 框架。使用标准的 Maven 方式进行打包，部署，同时也可以采用前后端分离的方式本地运行，方便开发调试。</p><h3 id="ShardingSphere-Sidecar（TODO）"><a href="#ShardingSphere-Sidecar（TODO）" class="headerlink" title="ShardingSphere-Sidecar（TODO）"></a>ShardingSphere-Sidecar（TODO）</h3><p>定位为 Kubernetes 的云原生数据库代理，以 Sidecar 的形式代理所有对数据库的访问。 通过无中心、零侵入的方案提供与数据库交互的的啮合层，即 <code>Database Mesh</code>，又可称数据库网格。</p><p>Database Mesh 的关注重点在于如何将分布式的数据访问应用与数据库有机串联起来，它更加关注的是交互，是将杂乱无章的应用与数据库之间的交互进行有效地梳理。 使用 Database Mesh，访问数据库的应用和数据库终将形成一个巨大的网格体系，应用和数据库只需在网格体系中对号入座即可，它们都是被啮合层所治理的对象。</p><p><img src="/images/shardingsphere-introduce/shardingsphere-sidecar-brief.png" alt="ShardingSphere-Sidecar Architecture"></p><table><thead><tr><th align="left"></th><th align="left"><em>ShardingSphere-JDBC</em></th><th align="left"><em>ShardingSphere-Proxy</em></th><th align="left"><em>ShardingSphere-Sidecar</em></th></tr></thead><tbody><tr><td align="left">数据库</td><td align="left">任意</td><td align="left">MySQL/PostgreSQL</td><td align="left">MySQL/PostgreSQL</td></tr><tr><td align="left">连接消耗数</td><td align="left">高</td><td align="left">低</td><td align="left">高</td></tr><tr><td align="left">异构语言</td><td align="left">仅 Java</td><td align="left">任意</td><td align="left">任意</td></tr><tr><td align="left">性能</td><td align="left">损耗低</td><td align="left">损耗略高</td><td align="left">损耗低</td></tr><tr><td align="left">无中心化</td><td align="left">是</td><td align="left">否</td><td align="left">是</td></tr><tr><td align="left">静态入口</td><td align="left">无</td><td align="left">有</td><td align="left">无</td></tr></tbody></table><h3 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h3><p>ShardingSphere-JDBC采用无中心化架构，用于 Java 开发的高性能的轻量级应用。</p><p>ShardingSphere-Proxy 提供静态入口以及异构语言的支持，用于数据迁移及运维查询。</p><p>ShardingSphere-Scaling 用于数据迁移。</p><p><img src="/images/shardingsphere-introduce/image-20201216154030084.png" alt="image-20201216154030084"></p>]]></content>
    
    
    <categories>
      
      <category>shardingsphere</category>
      
    </categories>
    
    
    <tags>
      
      <tag>shardingsphere</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>shardingsphere之scaling</title>
    <link href="/2021/01/05/shardingsphere-scaling-introduce/"/>
    <url>/2021/01/05/shardingsphere-scaling-introduce/</url>
    
    <content type="html"><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>ShardingSphere-Scaling 是一个提供给用户的通用的 ShardingSphere 数据接入迁移，及弹性伸缩的解决方案。</p><h2 id="使用方式"><a href="#使用方式" class="headerlink" title="使用方式"></a>使用方式</h2><p>目前的弹性伸缩解决方案为：临时地使用两个数据库集群，伸缩完成后切换的方式实现。</p><p><img src="/images/shardingsphere-scaling-introduce/scaling-principle-overview.cn.png" alt="伸缩总揽"></p><p>这种实现方式有以下优点：</p><ol><li>伸缩过程中，原始数据没有任何影响</li><li>伸缩失败无风险</li><li>不受分片策略限制</li></ol><p>同时也存在一定的缺点：</p><ol><li>在一定时间内存在冗余服务器</li><li>所有数据都需要移动</li></ol><h2 id="执行步骤"><a href="#执行步骤" class="headerlink" title="执行步骤"></a>执行步骤</h2><p><img src="/images/shardingsphere-scaling-introduce/image-20201216161515781.png" alt="image-20201216161515781"></p><h3 id="准备阶段"><a href="#准备阶段" class="headerlink" title="准备阶段"></a>准备阶段</h3><p>在准备阶段，弹性伸缩模块会进行数据源连通性及权限的校验，同时进行存量数据的统计、日志位点的记录，最后根据数据量和用户设置的并行度，对任务进行分片。</p><h3 id="存量数据迁移阶段"><a href="#存量数据迁移阶段" class="headerlink" title="存量数据迁移阶段"></a>存量数据迁移阶段</h3><p>执行在准备阶段拆分好的存量数据迁移作业，存量迁移阶段采用 JDBC 查询的方式，直接从数据节点中读取数据，并使用新规则写入到新集群中。</p><h3 id="增量数据同步阶段"><a href="#增量数据同步阶段" class="headerlink" title="增量数据同步阶段"></a>增量数据同步阶段</h3><p>由于存量数据迁移耗费的时间受到数据量和并行度等因素影响，此时需要对这段时间内业务新增的数据进行同步。 不同的数据库使用的技术细节不同，但总体上均为基于复制协议或 WAL 日志实现的变更数据捕获功能。</p><ul><li>MySQL：订阅并解析 binlog</li><li>PostgreSQL：采用官方逻辑复制 <a href="https://www.postgresql.org/docs/9.4/test-decoding.html">test_decoding</a></li></ul><p>这些捕获的增量数据，同样会由弹性伸缩模块根据新规则写入到新数据节点中。当增量数据基本同步完成时（由于业务系统未停止，增量数据是不断的），则进入规则切换阶段。</p><h3 id="规则切换阶段"><a href="#规则切换阶段" class="headerlink" title="规则切换阶段"></a>规则切换阶段</h3><p>在此阶段，可能存在一定时间的业务只读窗口期，通过业务停止写入或设置数据库只读或ShardingSphere的熔断机制，让旧数据节点中的数据短暂静态，确保增量同步已完全完成。</p><p>这个窗口期时间短则数秒，长则数分钟，取决于数据量和用户是否需要对数据进行强校验。 确认完成后，Apache ShardingSphere 可通过配置中心修改配置，将业务导向新规则的集群，弹性伸缩完成。</p><p>我们由于有写业务无法无法完全停止写入，目前只能尽可能减少写入，然后开启双写，并且停止迁移，进行数据校验，对有问题数据进行补处理。</p><h2 id="架构设计"><a href="#架构设计" class="headerlink" title="架构设计"></a>架构设计</h2><h3 id="ScalingTask"><a href="#ScalingTask" class="headerlink" title="ScalingTask"></a>ScalingTask</h3><p>任务最小执行单元</p><p>主要实现类：</p><ul><li>InventoryDataScalingTask（History）存量</li><li>IncrementalDataScalingTask（RealTime） 增量</li></ul><h3 id="Dumper（Reader）"><a href="#Dumper（Reader）" class="headerlink" title="Dumper（Reader）"></a>Dumper（Reader）</h3><p>从原库获取数据，核心操作主要有：</p><ul><li>setChannel(Channel channel); 设置Channel</li><li>dump(); 从原库获取数据，并保存数据到channel中</li></ul><p>主要实现类：</p><ul><li>JDBCDumper</li><li>LogDumper</li></ul><h3 id="Importer（Writer）"><a href="#Importer（Writer）" class="headerlink" title="Importer（Writer）"></a>Importer（Writer）</h3><p>把数据写入数据到新库,核心操作主要有：</p><ul><li>setChannel(Channel channel); 设置Channel</li><li>write(); 写入数据到数据库</li></ul><h3 id="Channel"><a href="#Channel" class="headerlink" title="Channel"></a>Channel</h3><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">interface</span> <span class="hljs-title">Channel</span> </span>&#123;    <span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">pushRecord</span><span class="hljs-params">(Record dataRecord)</span> <span class="hljs-keyword">throws</span> InterruptedException</span>;    <span class="hljs-function">List&lt;Record&gt; <span class="hljs-title">fetchRecords</span><span class="hljs-params">(<span class="hljs-keyword">int</span> batchSize, <span class="hljs-keyword">int</span> timeout)</span></span>;    <span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">ack</span><span class="hljs-params">()</span></span>;    <span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">close</span><span class="hljs-params">()</span></span>;&#125;</code></pre><p>主要实现类：</p><ul><li>MemoryChannel</li><li>DistributionChannel</li></ul><h3 id="存量迁移"><a href="#存量迁移" class="headerlink" title="存量迁移"></a>存量迁移</h3><p><img src="/images/shardingsphere-scaling-introduce/image-20201216175534892.png" alt="image-20201216175534892"></p><ol><li><p>获取minId、maxId，并根据id和concurrency 把迁移id区间平均分配到各个Task（InventoryDataScalingTask）。</p><p>minId=1，maxId=100，concurrency=10，则</p><p>task1 id区间为 1<del>10，task2 id区间为 11</del>20 ……</p></li><li><p>每个Task都有一个dumper 从原库批量获取DataRecord，并push到MemoryChannel，BlockingQueue长度为10000，超过则阻塞等待</p></li><li><p>Importer从MemoryChannel批量获取DataRecord并依次插入到新库中，然后ack()。</p></li><li><p>当dumper获取不到数据时，则push一个FinishedRecord到MemoryChannel，dumper结束。</p></li><li><p>Importer获取到FinishedRecord时，Importer结束，Task执行完毕。</p></li></ol><h3 id="增量迁移"><a href="#增量迁移" class="headerlink" title="增量迁移"></a>增量迁移</h3><p><img src="/images/shardingsphere-scaling-introduce/image-20201216175621918.png" alt="image-20201216175621918"></p><ol><li><p>每次Task（InventoryDataScalingTask）执行完成，callBack 检测是否所有Task（InventoryDataScalingTask）执行完成。都执行完成开启增量迁移Task（IncrementalDataScalingTask）。</p></li><li><p>增量只有一个dumper 从迁移开始时记录的binlog位置subscribe数据，并根据hashcode和channelNumber取模push到Memorychannel。</p><p>String index = Integer.toString(Math.abs(dataRecord.hashCode()) % channelNumber);</p></li><li><p>Importer从MemoryChannel批量获取DataRecord并依次插入/更新到新库中，然后ack()。</p></li></ol>]]></content>
    
    
    <categories>
      
      <category>shardingsphere</category>
      
    </categories>
    
    
    <tags>
      
      <tag>shardingsphere</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>netty-start</title>
    <link href="/2020/12/18/netty-start/"/>
    <url>/2020/12/18/netty-start/</url>
    
    <content type="html"><![CDATA[<p>Netty 是一款异步的事件驱动的网络应用程序框架，支持快速地开发可维护的高性能的面向协议的服务器</p><p>和客户端。</p><p><img src="/images/netty-start/image-20201218173515498.png" alt="image-20201218173515498"></p><p>FTP</p><p>SMTP</p><p>HTTP</p><p>WebSocket</p>]]></content>
    
    
    <categories>
      
      <category>netty</category>
      
    </categories>
    
    
    <tags>
      
      <tag>netty</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>shardingsphere之mysql数据迁移优化</title>
    <link href="/2020/12/04/shardingsphere-sacling-mysql-speed-increase/"/>
    <url>/2020/12/04/shardingsphere-sacling-mysql-speed-increase/</url>
    
    <content type="html"><![CDATA[<p>水平分库项目，用了ShardingSphere-scaling做数据迁移，由于存量数据迁移过程中过于缓慢，对数据迁移模块进行优化。</p><p>迁移效率提升600%，校验效率提升6000%。</p><table><thead><tr><th>表名</th><th>数据</th><th>迁移耗时</th><th>校验耗时</th></tr></thead><tbody><tr><td>screen_case</td><td>16000w</td><td>12h（优化前）</td><td></td></tr><tr><td>dc_rule_random</td><td>7000w</td><td>1h</td><td>8h（优化前）</td></tr><tr><td>ap_apply</td><td>14000w</td><td>2h</td><td>14m</td></tr><tr><td>ap_apply_ext</td><td>17000w</td><td>4h2m</td><td>18m</td></tr></tbody></table><h2 id="批量插入"><a href="#批量插入" class="headerlink" title="批量插入"></a>批量插入</h2><p><code>rewriteBatchedStatements=true</code></p><p>改写存量数据为批量插入，代码如下：</p><pre><code class="hljs java"><span class="hljs-keyword">try</span> (Connection connection = dataSource.getConnection()) &#123;    connection.setAutoCommit(<span class="hljs-keyword">false</span>);    <span class="hljs-keyword">try</span> (PreparedStatement ps = connection.prepareStatement(insertSql)) &#123;        ps.setQueryTimeout(<span class="hljs-number">60</span>);        <span class="hljs-keyword">for</span> (DataRecord record : list) &#123;            <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; record.getColumnCount(); i++) &#123;                ps.setObject(i + <span class="hljs-number">1</span>, record.getColumn(i).getValue());            &#125;            ps.addBatch();        &#125;        ps.executeBatch();    &#125;    connection.commit();&#125;</code></pre><p>当时以为这样写就可以了，但是迁移速度还是很慢只比原来单条插入快了一倍左右，经过研究发现，这并不是真正的批量插入，只是多条插入一次事务，降低了事务开销。</p><pre><code class="hljs mysql">INSERT IGNORE INTO &#96;user&#96;(&#96;id&#96;,&#96;cust_no&#96;,&#96;age&#96;,&#96;name&#96;,&#96;delete_at&#96;) VALUES(59985,&#39;UR59985&#39;,98,&#39;name:1605538600723&#39;,0) ;INSERT IGNORE INTO &#96;user&#96;(&#96;id&#96;,&#96;cust_no&#96;,&#96;age&#96;,&#96;name&#96;,&#96;delete_at&#96;) VALUES(59986,&#39;UR59986&#39;,23,&#39;name:160512312311&#39;,0) ;</code></pre><p>在 MySQL JDBC 中，批操作的提交默认是逐条进行的。而在链接中加入以下参数，会把多条语句合并成一条提交。当 SQL 语句累积到一定数量（由数据库可接受的最大数据包大小决定），再一次性提交到数据库，减少了与数据库的交互次数，大大提高了效率。<code>rewriteBatchedStatements=true</code></p><pre><code class="hljs mysql">INSERT IGNORE INTO &#96;user&#96;(&#96;id&#96;,&#96;cust_no&#96;,&#96;age&#96;,&#96;name&#96;,&#96;delete_at&#96;) VALUES(50200,&#39;UR50200&#39;,98,&#39;name:1606138884516&#39;,0),(50202,&#39;UR50202&#39;,98,&#39;name:1606138884516&#39;,0),(50204,&#39;UR50204&#39;,98,&#39;name:1606138884516&#39;,0);</code></pre><p>分析源码可以发现：<br>当mysql版本&gt;4.1.1，并且rewriteBatchedStatements=true，批操作语句总数大于 4 条时（nbrCommands &gt; 4），才会合并成一条语句提交。</p><pre><code class="hljs java">com.mysql.jdbc.StatementImpl#executeBatchInternal  <span class="hljs-keyword">protected</span> <span class="hljs-keyword">long</span>[] executeBatchInternal() <span class="hljs-keyword">throws</span> SQLException &#123;...nbrCommands = (<span class="hljs-keyword">long</span>[])<span class="hljs-keyword">this</span>.batchedArgs.size();<span class="hljs-comment">// 获取批操作语句数量</span>    <span class="hljs-keyword">this</span>.batchedGeneratedKeys = <span class="hljs-keyword">new</span> ArrayList(<span class="hljs-keyword">this</span>.batchedArgs.size());    <span class="hljs-keyword">boolean</span> multiQueriesEnabled = locallyScopedConn.getAllowMultiQueries();<span class="hljs-comment">// 当前连接是否允许一次查询多条语句，默认为 false</span>    Object sqlEx;<span class="hljs-keyword">if</span> (locallyScopedConn.versionMeetsMinimum(<span class="hljs-number">4</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>) &amp;&amp; (multiQueriesEnabled || locallyScopedConn.getRewriteBatchedStatements() &amp;&amp; nbrCommands &gt; <span class="hljs-number">4</span>)) &#123;sqlEx = <span class="hljs-keyword">this</span>.executeBatchUsingMultiQueries(multiQueriesEnabled, (<span class="hljs-keyword">int</span>)nbrCommands, individualStatementTimeout);    <span class="hljs-keyword">return</span> (<span class="hljs-keyword">long</span>[])sqlEx;    &#125;    ...&#125;</code></pre><h2 id="预编译设置"><a href="#预编译设置" class="headerlink" title="预编译设置"></a>预编译设置</h2><p> jdbc客户端参数：</p><p>  cachePrepStmts：默认false.是否缓存prepareStatement对象。每个连接都有一个缓存，是以sql为唯一标识的LRU cache. 同一连接下，不同stmt可以不用重新创建prepareStatement对象。</p><p>  prepStmtCacheSize：LRU cache中prepareStatement对象的个数。一般设置为最常用sql的个数。</p><p>  prepStmtCacheSqlLimit：prepareStatement对象的大小。超出大小不缓存。</p><h2 id="服务端编译"><a href="#服务端编译" class="headerlink" title="服务端编译"></a>服务端编译</h2><p>useServerPrepStmts=false 关闭服务器端编译，sql语句在客户端编译好再发送给服务器端。</p><p>如果为true,sql会采用占位符方式发送到服务器端，在服务器端再组装sql语句。</p><p>占位符方式：<code>INSERT INTO t (c1,c2) VALUES (？,？),(？,？),(？,？);</code></p><p>此方式就会产生一个问题，当列数*提交记录数&gt;65535</p><p>时就会报错：Prepared statement contains too many placeholders,</p><p>这是由于我把“提交记录数量”设为10000，而要插入记录的表字段有30个，所以要进行批量插入时需要30*10000=300000  &gt; 65535 ，故而报错。</p><p><strong>解决方案</strong></p><p><strong>方案1：</strong>把DB连接中的 rewriteBatchedStatements 给设置为false（或者去掉），不过这个操作会影响数据的插入速度。</p><p><strong>方案2：</strong>更改表输出的设计。确保30个输出字段的和提交记录数量的乘积不超过65535。比如把提交记录数量由10000更改为450（30*2000=60000&lt; 65535）</p><p>当然我们的目的是为了提高数据库写速度，并且不考虑sql注入问题，所以当<code>rewriteBatchedStatements =true</code>时<code>useServerPrepStmts=false</code>配合使用较为合适。</p><h2 id="压缩数据传输"><a href="#压缩数据传输" class="headerlink" title="压缩数据传输"></a>压缩数据传输</h2><p><code>useCompression=true</code>压缩数据传输，优化客户端和MySQL服务器之间的通信性能。</p><pre><code class="hljs java">com.mysql.jdbc.MysqlIO#doHandshake<span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">doHandshake</span><span class="hljs-params">(String user, String password, String database)</span> <span class="hljs-keyword">throws</span> SQLException </span>&#123; ···          <span class="hljs-comment">//</span>    <span class="hljs-comment">// Can&#x27;t enable compression until after handshake 在握手后</span>    才能启用压缩    <span class="hljs-comment">//</span>    <span class="hljs-keyword">if</span> (((<span class="hljs-keyword">this</span>.serverCapabilities &amp; CLIENT_COMPRESS) != <span class="hljs-number">0</span>) &amp;&amp; <span class="hljs-keyword">this</span>.connection.getUseCompression() &amp;&amp; !(<span class="hljs-keyword">this</span>.mysqlInput <span class="hljs-keyword">instanceof</span> CompressedInputStream)) &#123;        <span class="hljs-comment">// The following matches with ZLIB&#x27;s compress()</span>        <span class="hljs-keyword">this</span>.deflater = <span class="hljs-keyword">new</span> Deflater();        <span class="hljs-keyword">this</span>.useCompression = <span class="hljs-keyword">true</span>;        <span class="hljs-keyword">this</span>.mysqlInput = <span class="hljs-keyword">new</span> CompressedInputStream(<span class="hljs-keyword">this</span>.connection, <span class="hljs-keyword">this</span>.mysqlInput);    &#125;···&#125;</code></pre><p><a href="https://dev.mysql.com/doc/refman/5.7/en/server-system-variables.html#sysvar_have_compress">https://dev.mysql.com/doc/refman/5.7/en/server-system-variables.html#sysvar_have_compress</a></p><p><img src="/images/shardingsphere-sacling-mysql-speed-increase/image-20201124001333217.png" alt="image-20201124001333217"></p><p>压缩协议提升网络传输性能，对于一些网络环境较差的用户会有很大的帮助，但是会相应地增加CPU开销，适用于传输数据量很大带宽不高的情况，这是一个CPU和网络资源的平衡问题。</p><p>经过测试 直连数据库会速度提高 5% 左右，效果不明显。通过shardingsphere-proxy连接数据库速度也并无明显提升</p><p>因此目前带宽无瓶颈的情况下，未使用压缩协议</p><p>直连数据库批量插入5分钟：</p><table><thead><tr><th>useCompression</th><th>100条avg</th><th>1000条avg</th><th>10000条avg</th></tr></thead><tbody><tr><td>true</td><td>11ms</td><td>42ms</td><td>307ms</td></tr><tr><td>false</td><td>12ms</td><td>43ms</td><td>321ms</td></tr></tbody></table><p>通过shardingsphere-proxy连接数据库批量插入5分钟：</p><table><thead><tr><th>useCompression</th><th>100条avg</th><th>1000条avg</th><th>10000条avg</th></tr></thead><tbody><tr><td>true</td><td>31ms</td><td>101ms</td><td>725ms</td></tr><tr><td>false</td><td>32ms</td><td>100ms</td><td>732ms</td></tr></tbody></table><p><strong>适用场景</strong></p><p>MySQL 压缩协议适合的场景是 MySQL 的服务器端和客户端之间传输的数据量很大，或者可用带宽不高的情况，典型的场景有如下两个：</p><p>a、查询大量的数据，带宽不够（比如导出数据的时候）；</p><p>b、复制的时候 binlog 量太大，启用 slave_compressed_protocol 参数进行日志压缩复制。</p><h3 id="压缩协议简介"><a href="#压缩协议简介" class="headerlink" title="压缩协议简介"></a>压缩协议简介</h3><p>压缩协议是 MySQL 通信协议的一部分，要启用压缩协议进行数据传输，需要 MySQL 服务器端和客户端都支持 zlib 算法。启动压缩协议会导致 CPU 负载略微上升。使用启用压缩协议使用-C 参数或者 –compress=true 参数启动客户端的压缩功能。如果启用了-C 或者 compress=true 选项，那么在连接到服务器段的时候，会发送 0x0020（CLIENT_COMPRESS）的服务器权能标志位，和服务器端协商通过后（3 次握手以后），就支持压缩协议了。由于采用压缩，数据包的格式会发生变化，具体的变化如下：</p><p>未压缩的数据包格式：</p><p><img src="/images/shardingsphere-sacling-mysql-speed-increase/1497240545250_627_1497240545431.png" alt="img"></p><p>压缩后的数据包格式：</p><p><img src="/images/shardingsphere-sacling-mysql-speed-increase/1497240560529_3423_1497240560716.png" alt="img"></p><p>大家可能留意到压缩后的数据报格式有压缩和未压缩之分，这个是 MySQL 为了较少 CPU 开销而做的一个优化。如果内容小于 50 个字节的时候，就不对内容进行压缩，而大于 50 字节的时候，才会启用压缩功能。具体的规则如下：</p><p>当第三个字段的值等于 0x00 的时候，表示当前包没有压缩，因此 n<code>*</code>byte 的内容为 1<code>*</code>byte,n<code>*</code>byte，即请求类型和请求内容。</p><p>当第三个字段的值大于 0x00 的时候，表示当前包已采用 zlib 压缩，因此使用的时候需要对 n<code>*</code>byte 进行解压，解压后内容为 1<code>*</code>byte,n<code>*</code>byte，即请求类型和请求内容。</p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p><strong>原库读取数据设置</strong></p><p><code>useServerPrepStmts=true</code><br><code>cachePrepStmts=true</code></p><p><strong>新库插入数据设置</strong></p><p><code>rewriteBatchedStatements=true </code><br><code>useServerPrepStmts=false </code><br><code>useCompression=false</code></p><h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><p><a href="https://my.oschina.net/u/4418437/blog/3648369">https://my.oschina.net/u/4418437/blog/3648369</a><br><a href="https://cloud.tencent.com/developer/article/1005252">https://cloud.tencent.com/developer/article/1005252</a><br><a href="https://www.cnblogs.com/lispking/p/3604063.html">https://www.cnblogs.com/lispking/p/3604063.html</a><br><a href="https://stackoverflow.com/questions/2506460/when-should-i-use-mysql-compressed-protocol">https://stackoverflow.com/questions/2506460/when-should-i-use-mysql-compressed-protocol</a><br><a href="https://blog.csdn.net/qq_43153418/article/details/104002252">https://blog.csdn.net/qq_43153418/article/details/104002252</a><br><a href="https://www.cnblogs.com/justfortaste/p/3920140.html">https://www.cnblogs.com/justfortaste/p/3920140.html</a></p>]]></content>
    
    
    <categories>
      
      <category>shardingsphere</category>
      
    </categories>
    
    
    <tags>
      
      <tag>shardingsphere</tag>
      
      <tag>mysql</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>AOP遇到的问题</title>
    <link href="/2020/10/29/AOP%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98/"/>
    <url>/2020/10/29/AOP%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98/</url>
    
    <content type="html"><![CDATA[<p>test1</p>]]></content>
    
    
    
    <tags>
      
      <tag>JAVA</tag>
      
      <tag>AOP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2020/10/01/hello-world/"/>
    <url>/2020/10/01/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span></code></pre><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre><code class="hljs bash">$ hexo server</code></pre><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre><code class="hljs bash">$ hexo generate</code></pre><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre><code class="hljs bash">$ hexo deploy</code></pre><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
